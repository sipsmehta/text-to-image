{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text to Image using Stable Diffusion by Sparsh Mehta"
      ],
      "metadata": {
        "id": "ZuYZNq3mbUUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages"
      ],
      "metadata": {
        "id": "4R8MbyewbdBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate\n"
      ],
      "metadata": {
        "id": "XH1E7O50455e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparative Experiments for different Diffusion Models with different prompts and parameters"
      ],
      "metadata": {
        "id": "q9qGDfSxbimu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler, LMSDiscreteScheduler, DPMSolverMultistepScheduler\n",
        "from PIL import Image\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the models and their respective schedulers\n",
        "models = [\n",
        "    (\"stabilityai/stable-diffusion-2-1\", EulerDiscreteScheduler),\n",
        "    (\"stabilityai/stable-diffusion-2\", EulerDiscreteScheduler),\n",
        "    (\"runwayml/stable-diffusion-v1-5\", LMSDiscreteScheduler),\n",
        "]\n",
        "\n",
        "# Define the prompts to test\n",
        "prompts = [\n",
        "    \"An elderly man with a wrinkled face, kind eyes, and a warm smile, sitting on a wooden bench in a peaceful park, surrounded by autumn foliage, digital painting, 4k resolution\",\n",
        "    \"A majestic lion with a golden mane, sitting atop a rocky cliff, overlooking a vast savanna at sunset, photorealistic, 8k resolution\",\n",
        "    \"A futuristic cityscape with towering skyscrapers, flying cars, and neon lights, in the style of Blade Runner, cinematic, 4k resolution\",\n",
        "]\n",
        "\n",
        "# Define the settings to experiment with\n",
        "num_inference_steps_list = [25, 50, 100, 150]\n",
        "guidance_scale_list = [5.0, 7.5, 10.0, 12.0]\n",
        "\n",
        "# Store the comparison metrics in a list of dictionaries\n",
        "comparison_metrics = []\n",
        "\n",
        "# Set the base folder on Google Drive\n",
        "base_folder = '/content/drive/MyDrive/results'\n",
        "\n",
        "# Generate images for each combination of model, prompt, and settings\n",
        "for model_id, scheduler_cls in models:\n",
        "    model_name = model_id.split('/')[-1]\n",
        "    model_folder = f\"{base_folder}/{model_name}\"\n",
        "    os.makedirs(model_folder, exist_ok=True)\n",
        "\n",
        "    for prompt in prompts:\n",
        "        prompt_folder = f\"{model_folder}/{prompt[:50]}\"\n",
        "        os.makedirs(prompt_folder, exist_ok=True)\n",
        "\n",
        "        comparison_images = []\n",
        "\n",
        "        for num_inference_steps in num_inference_steps_list:\n",
        "            for guidance_scale in guidance_scale_list:\n",
        "                # Load the model and scheduler\n",
        "                scheduler = scheduler_cls.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "                pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "                pipe = pipe.to(\"cuda\")\n",
        "\n",
        "                # Generate the image and measure the time taken\n",
        "                start_time = time.time()\n",
        "                image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "                end_time = time.time()\n",
        "                generation_time = end_time - start_time\n",
        "\n",
        "                # Save the image with the model, prompt, and settings information\n",
        "                image_name = f\"{num_inference_steps}steps_{guidance_scale}scale.png\"\n",
        "                image_path = f\"{prompt_folder}/{image_name}\"\n",
        "                image.save(image_path)\n",
        "\n",
        "                # Store the comparison metrics\n",
        "                comparison_metrics.append({\n",
        "                    \"Model\": model_name,\n",
        "                    \"Prompt\": prompt[:50],\n",
        "                    \"Inference Steps\": num_inference_steps,\n",
        "                    \"Guidance Scale\": guidance_scale,\n",
        "                    \"Generation Time (s)\": round(generation_time, 2),\n",
        "                    \"Image Path\": image_path\n",
        "                })\n",
        "\n",
        "                comparison_images.append(image)\n",
        "\n",
        "        # Create a comparison image grid\n",
        "        num_cols = len(num_inference_steps_list)\n",
        "        num_rows = len(guidance_scale_list)\n",
        "        grid_image = Image.new('RGB', (num_cols * image.width, num_rows * image.height))\n",
        "\n",
        "        for i, img in enumerate(comparison_images):\n",
        "            row = i // num_cols\n",
        "            col = i % num_cols\n",
        "            grid_image.paste(img, (col * image.width, row * image.height))\n",
        "\n",
        "        comparison_image_path = f\"{prompt_folder}/comparison.png\"\n",
        "        grid_image.save(comparison_image_path)\n",
        "\n",
        "# Display the comparison metrics in a tabular format\n",
        "headers = [\"Model\", \"Prompt\", \"Inference Steps\", \"Guidance Scale\", \"Generation Time (s)\", \"Image Path\"]\n",
        "rows = []\n",
        "for metric in comparison_metrics:\n",
        "    row = [\n",
        "        metric[\"Model\"],\n",
        "        metric[\"Prompt\"],\n",
        "        metric[\"Inference Steps\"],\n",
        "        metric[\"Guidance Scale\"],\n",
        "        metric[\"Generation Time (s)\"],\n",
        "        metric[\"Image Path\"]\n",
        "    ]\n",
        "    rows.append(row)\n",
        "\n",
        "table = tabulate(rows, headers=headers, tablefmt=\"grid\")\n",
        "print(table)"
      ],
      "metadata": {
        "id": "5YwYtHqMGvLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "headers = [\"Model\", \"Prompt\", \"Inference Steps\", \"Guidance Scale\", \"Generation Time (s)\", \"Image Path\"]\n",
        "rows = []\n",
        "for metric in comparison_metrics:\n",
        "    row = [\n",
        "        metric[\"Model\"],\n",
        "        metric[\"Prompt\"],\n",
        "        metric[\"Inference Steps\"],\n",
        "        metric[\"Guidance Scale\"],\n",
        "        metric[\"Generation Time (s)\"],\n",
        "        metric[\"Image Path\"]\n",
        "    ]\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows, columns=headers)\n",
        "df.sort_values(by=\"Generation Time (s)\",inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "t36PdnOnePqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "headers = [\"Model\", \"Prompt\", \"Inference Steps\", \"Guidance Scale\", \"Generation Time (s)\", \"Image Path\"]\n",
        "rows = []\n",
        "\n",
        "for metric in comparison_metrics:\n",
        "    row = [\n",
        "        metric[\"Model\"],\n",
        "        metric[\"Prompt\"],\n",
        "        metric[\"Inference Steps\"],\n",
        "        metric[\"Guidance Scale\"],\n",
        "        metric[\"Generation Time (s)\"],\n",
        "        metric[\"Image Path\"]\n",
        "    ]\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows, columns=headers)\n",
        "\n",
        "# Get the minimum \"Generation Time (s)\" for each unique model\n",
        "min_generation_time = df.groupby('Model')['Generation Time (s)'].min().reset_index()\n",
        "\n",
        "print(min_generation_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2n2v33RjiHr",
        "outputId": "37b59113-985f-4fba-d7b4-6461fa735b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Model  Generation Time (s)\n",
            "0     stable-diffusion-2                 3.59\n",
            "1   stable-diffusion-2-1                 3.47\n",
            "2  stable-diffusion-v1-5                 1.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "import torch\n",
        "\n",
        "# Set up the model\n",
        "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Get user input for the prompt\n",
        "prompt = \"a photorealistic image of a man sitting in a cafe working on his laptop and cup of coffee on a desk\"\n",
        "\n",
        "# Set up image generation parameters\n",
        "num_inference_steps = 100\n",
        "guidance_scale = 7.5\n",
        "\n",
        "# Generate the initial image\n",
        "image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "# Display the initial image\n",
        "display(image)\n",
        "\n",
        "# Upscale the image to 2048x2048 resolution\n",
        "from PIL import Image\n",
        "upscaled_image = image.resize((2048, 2048), resample=Image.LANCZOS)\n",
        "\n",
        "# Display the upscaled image\n",
        "display(upscaled_image)\n",
        "\n",
        "# Save the upscaled image\n",
        "upscaled_image.save(\"upscaled_image.png\")"
      ],
      "metadata": {
        "id": "QUD9oiws__t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "\n",
        "# Import necessary modules\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "import torch\n",
        "\n",
        "# Set up the model\n",
        "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Get user input for the prompt\n",
        "prompt = \"A magical forest with bioluminescent plants, enchanted creatures, and a mystical portal, fantasy art style, highly detailed, 8k resolution\"\n",
        "\n",
        "# Set up image generation parameters\n",
        "num_inference_steps = 100\n",
        "guidance_scale = 7.5\n",
        "\n",
        "# Generate the initial image\n",
        "image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "# Display the initial image\n",
        "display(image)\n",
        "\n",
        "# Upscale the image to 2048x2048 resolution\n",
        "from PIL import Image\n",
        "upscaled_image = image.resize((2048, 2048), resample=Image.LANCZOS)\n",
        "\n",
        "# Display the upscaled image\n",
        "display(upscaled_image)\n",
        "\n",
        "# Save the upscaled image\n",
        "upscaled_image.save(\"upscaled_image.png\")"
      ],
      "metadata": {
        "id": "zPFJ5tCi3wrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "\n",
        "# Import necessary modules\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "import torch\n",
        "\n",
        "# Set up the model\n",
        "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Get user input for the prompt\n",
        "prompt = \"An elderly man with a wrinkled face, kind eyes, and a warm smile, sitting on a wooden bench in a peaceful park, surrounded by autumn foliage, digital painting, 4k resolution\"\n",
        "\n",
        "# Set up image generation parameters\n",
        "num_inference_steps = 100\n",
        "guidance_scale = 7.5\n",
        "\n",
        "# Generate the initial image\n",
        "image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "# Display the initial image\n",
        "display(image)\n",
        "\n",
        "# Upscale the image to 2048x2048 resolution\n",
        "from PIL import Image\n",
        "upscaled_image = image.resize((2048, 2048), resample=Image.LANCZOS)\n",
        "\n",
        "# Display the upscaled image\n",
        "display(upscaled_image)\n",
        "\n",
        "# Save the upscaled image\n",
        "upscaled_image.save(\"upscaled_image.png\")"
      ],
      "metadata": {
        "id": "-_bbLEyhBJne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "import torch\n",
        "\n",
        "model_id = \"stabilityai/stable-diffusion-2\"\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"An elderly man with a wrinkled face, kind eyes, and a warm smile, sitting on a wooden bench in a peaceful park, surrounded by autumn foliage, digital painting, 4k resolution\"\n",
        "num_inference_steps = 100\n",
        "guidance_scale = 7.5\n",
        "\n",
        "image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "display(image)"
      ],
      "metadata": {
        "id": "_kI0CNxyF5Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
        "import torch\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "scheduler = LMSDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"An elderly man with a wrinkled face, kind eyes, and a warm smile, sitting on a wooden bench in a peaceful park, surrounded by autumn foliage, digital painting, 4k resolution\"\n",
        "num_inference_steps = 100\n",
        "guidance_scale = 7.5\n",
        "\n",
        "image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "display(image)"
      ],
      "metadata": {
        "id": "SKyUaQ_vF8QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionUpscalePipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
        "pipe = StableDiffusionUpscalePipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "low_res_image = image  # Use the image generated from Stable Diffusion 1.5 or 2.0\n",
        "\n",
        "prompt = \"An elderly man with a wrinkled face, kind eyes, and a warm smile, sitting on a wooden bench in a peaceful park, surrounded by autumn foliage, digital painting, 4k resolution\"\n",
        "upscaled_image = pipe(prompt=prompt, image=low_res_image).images[0]\n",
        "\n",
        "display(upscaled_image)"
      ],
      "metadata": {
        "id": "km4fpBgWGGFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler, LMSDiscreteScheduler, DPMSolverMultistepScheduler\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Define the models and their respective schedulers\n",
        "models = [\n",
        "    (\"stabilityai/stable-diffusion-2-1\", EulerDiscreteScheduler),\n",
        "    (\"stabilityai/stable-diffusion-2\", EulerDiscreteScheduler),\n",
        "    (\"runwayml/stable-diffusion-v1-5\", LMSDiscreteScheduler),\n",
        "]\n",
        "\n",
        "# Define the prompts to test\n",
        "prompts = [\n",
        "    \"An elderly man with a wrinkled face, kind eyes, and a warm smile, sitting on a wooden bench in a peaceful park, surrounded by autumn foliage, digital painting, 4k resolution\",\n",
        "    \"A majestic lion with a golden mane, sitting atop a rocky cliff, overlooking a vast savanna at sunset, photorealistic, 8k resolution\",\n",
        "    \"A futuristic cityscape with towering skyscrapers, flying cars, and neon lights, in the style of Blade Runner, cinematic, 4k resolution\",\n",
        "]\n",
        "\n",
        "# Define the settings to experiment with\n",
        "num_inference_steps_list = [25, 50, 100, 150]\n",
        "guidance_scale_list = [5.0, 7.5, 10.0, 12.0]\n",
        "\n",
        "# Generate images for each combination of model, prompt, and settings\n",
        "for model_id, scheduler_cls in models:\n",
        "    for prompt in prompts:\n",
        "        for num_inference_steps in num_inference_steps_list:\n",
        "            for guidance_scale in guidance_scale_list:\n",
        "                # Load the model and scheduler\n",
        "                scheduler = scheduler_cls.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "                pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "                pipe = pipe.to(\"cuda\")\n",
        "\n",
        "                # Generate the image and measure the time taken\n",
        "                start_time = time.time()\n",
        "                image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "                end_time = time.time()\n",
        "                generation_time = end_time - start_time\n",
        "\n",
        "                # Save the image with the model, prompt, and settings information\n",
        "                image_name = f\"{model_id.split('/')[-1]}_{prompt[:50]}_{num_inference_steps}steps_{guidance_scale}scale.png\"\n",
        "                image.save(image_name)\n",
        "\n",
        "                # Print the generation time and image name\n",
        "                print(f\"Generation time for {image_name}: {generation_time:.2f} seconds\")\n",
        "\n",
        "        print(\"\\n\")  # Add a line break between prompts"
      ],
      "metadata": {
        "id": "7_85ClzSGI73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}